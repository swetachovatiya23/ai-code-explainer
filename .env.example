# =============================================================================
# AI Code Explainer - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# =============================================================================

# -----------------------------------------------------------------------------
# REQUIRED: Groq API Configuration
# -----------------------------------------------------------------------------

# Your Groq API key (get from https://console.groq.com)
GROQ_API_KEY=your_groq_api_key_here

# -----------------------------------------------------------------------------
# OPTIONAL: API Configuration
# -----------------------------------------------------------------------------

# API endpoint (WITHOUT /openai/v1 suffix - SDK adds it automatically)
GROQ_BASE_URL=https://api.groq.com

# AI model to use (must be a valid Groq model)
# Options:
#   - llama-3.3-70b-versatile (Recommended - Best quality)
#   - llama-3.1-8b-instant (Faster - Good for simple code)
#   - llama-3.1-70b-versatile (High quality alternative)
#   - mixtral-8x7b-32768 (Large context window)
#   - gemma2-9b-it (Google's efficient model)
GROQ_MODEL_NAME=llama-3.3-70b-versatile

# -----------------------------------------------------------------------------
# OPTIONAL: Application Settings
# -----------------------------------------------------------------------------

# Maximum number of code lines to analyze (default: 500)
MAX_CODE_LINES=500

# Maximum file upload size in MB (default: 5)
MAX_FILE_SIZE_MB=5

# -----------------------------------------------------------------------------
# OPTIONAL: API Mode Settings (only used with --mode api)
# -----------------------------------------------------------------------------

# FastAPI server host
API_HOST=0.0.0.0

# FastAPI server port
API_PORT=8000
